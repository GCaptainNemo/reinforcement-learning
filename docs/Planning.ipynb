{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 规划问题\n",
    "强化学习中规划(Planning)问题指环境模型已知的情况下，即$P_{ss'}^a$和$R_s^a$已知，寻找最优策略。求解规划问题算法包括策略迭代(policy iteration)、值函数迭代(value iteration)和线性规划(linear programming)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、值函数迭代 \n",
    "值函数迭代算法(Value iteration algorithm)又称为VI算法，从初始状态值函数开始，迭代更新状态值函数，直到达到最优状态值函数，对应的策略也就是最优策略。\n",
    "\n",
    "![value_iteration_algorithm](../resources/VI.png)\n",
    "\n",
    "### 1.1 VI算法的收敛性\n",
    "**定理**： 对任意的初始状态值函数$V_0$，由$V_{n+1} = \\Phi(V_n)$定义的迭代序列收敛到最优值函数$V^*$。\n",
    "\n",
    "**证明**: 首先构造关于值函数的度量空间，定义所有状态值函数构成的集合$X = \\{V|V \\in R^{|S|}\\}$，再在$X$上定义无穷范数$\\forall x \\in X, ||x||_\\infty = \\max_{i \\in [0, |S|]}|x_i|$，用无穷范数诱导度量$d$,则(X, d)就是一个度量空间。又因为该空间本身是欧式空间，故是完备的。\n",
    "\n",
    "$\\ \\Phi(V)(s) = \\max_{\\pi}\\{\\sum_{a\\in A} \\pi(a|s)[R_s^a + \\gamma \\sum_{s' \\in S}P_{ss'}^a V(s')]\\}$\n",
    "\n",
    "下面证明$\\Phi$是一个**压缩映射**,$\\forall u, v \\in X$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "||\\Phi(u) - \\Phi(v)||_{\\infty} &\\leq || \\gamma \\max_{\\pi}\\{\\sum_{a\\in A}\\sum_{s'\\in S}P_{ss'}^a \\pi(a|s) (u(s') - v(s'))\\}||_{\\infty} \\\\\n",
    "                     &\\leq \\gamma|| \\max_{\\pi, s'}\\{\\sum_{a\\in A}\\sum_{s'\\in S}P_{ss'}^a \\pi(a|s) (u(s') - v(s'))\\}||_\\infty \\\\\n",
    "                 &\\leq \\gamma  \\max_{\\pi, s'}\\{\\sum_{a\\in A}\\sum_{s'\\in S}P_{ss'}^a \\pi(a|s)\\} \\times ||(u(s') - v(s'))||_{\\infty} \\\\\n",
    "                 &\\leq \\gamma ||(u(s') - v(s'))||_{\\infty} \\\\\n",
    " \\end{aligned}$$\n",
    "\n",
    "因此$\\Phi$是一个**压缩映射**,由压缩映像定理(contraction mappint theorem)，算子$\\Phi$存在唯一不动点$\\bar{V}$，且任意初始值$V_0$的迭代序列$\\{\\Phi^n(V_0)\\}_{n=1,2,3,...}$收敛于该不动点。\n",
    "下面说明该不动点就是最优状态值函数$V^*$，假设该不动点不是最优状态值函数，则说明该不动点对应的策略也不是最优策略$\\pi^*$，而最优策略对应的值函数会大于$\\Phi(\\bar{V})$，与$\\bar{V}$是不动点矛盾，所以不动点是最优状态值函数。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、策略迭代\n",
    "\n",
    "![value_iteration_algorithm](../resources/PI.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
